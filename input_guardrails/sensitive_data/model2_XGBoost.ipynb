{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cxWAgexg-GuU"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "dataset = load_dataset(\"ai4privacy/pii-masking-300k\")\n",
        "train = load_dataset(\"ai4privacy/pii-masking-300k\", split = \"train\")\n",
        "test = load_dataset(\"ai4privacy/pii-masking-300k\", split = \"validation\")\n",
        "\n",
        "train = train.filter(lambda x: x[\"language\"] == \"English\")\n",
        "test = test.filter(lambda x: x[\"language\"] == \"English\")\n",
        "\n",
        "train_df = pd.DataFrame(train)\n",
        "test_df = pd.DataFrame(test)\n",
        "\n",
        "train_df[\"is_sensitive\"] = train_df[\"privacy_mask\"].apply(lambda x: 1 if len(x) > 0 else 0)\n",
        "test_df[\"is_sensitive\"] = test_df[\"privacy_mask\"].apply(lambda x: 1 if len(x) > 0 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# prepare the data\n",
        "X_train_texts = train_df[\"source_text\"]\n",
        "y_train = train_df[\"is_sensitive\"]\n",
        "\n",
        "X_test_texts = test_df[\"source_text\"]\n",
        "y_test = test_df[\"is_sensitive\"]\n",
        "\n",
        "# vectorize text with TF-IDF\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=20000,\n",
        "    ngram_range=(1, 2),\n",
        "    stop_words=\"english\"\n",
        ")\n",
        "\n",
        "X_train = vectorizer.fit_transform(X_train_texts)\n",
        "X_test = vectorizer.transform(X_test_texts)\n",
        "\n",
        "# train xgboost classifier\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"logloss\",\n",
        "    max_depth=None,\n",
        "    learning_rate=0.15,\n",
        "    n_estimators=500,\n",
        "    subsample=0.8, # random rows to prevent overfitting and add diversity\n",
        "    colsample_bytree=0.8, # random columns to reduces feature correlation\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# evaluate\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=3))\n",
        "\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "importances = xgb_clf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1][:20]\n",
        "\n",
        "print(\"\\nTop 20 Important Words for Sensitive Detection:\")\n",
        "for i in indices:\n",
        "    print(f\"{feature_names[i]}: {importances[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38IdgkusBu7j",
        "outputId": "253fa192-4b3a-469c-9f79-2547e11e3c35"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:28:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9181978353888749\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.687     0.522     0.593       908\n",
            "           1      0.940     0.969     0.955      7038\n",
            "\n",
            "    accuracy                          0.918      7946\n",
            "   macro avg      0.814     0.746     0.774      7946\n",
            "weighted avg      0.911     0.918     0.913      7946\n",
            "\n",
            "\n",
            "Top 20 Important Words for Sensitive Detection:\n",
            "com: 0.0154\n",
            "city: 0.0130\n",
            "number: 0.0098\n",
            "passport: 0.0086\n",
            "road: 0.0075\n",
            "username: 0.0073\n",
            "country: 0.0071\n",
            "ip: 0.0068\n",
            "eng: 0.0066\n",
            "street: 0.0061\n",
            "sex: 0.0054\n",
            "11: 0.0051\n",
            "license: 0.0044\n",
            "field: 0.0041\n",
            "hesitate: 0.0039\n",
            "clock: 0.0039\n",
            "id: 0.0037\n",
            "07: 0.0037\n",
            "postcode: 0.0036\n",
            "employees: 0.0033\n"
          ]
        }
      ]
    }
  ]
}