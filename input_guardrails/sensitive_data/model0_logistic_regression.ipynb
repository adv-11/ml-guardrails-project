{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# # load dataset\n",
        "# # dataset = load_dataset(\"ai4privacy/pii-masking-300k\")\n",
        "# train = load_dataset(\"ai4privacy/pii-masking-300k\", split = \"train\")\n",
        "# test = load_dataset(\"ai4privacy/pii-masking-300k\", split = \"validation\")\n",
        "\n",
        "# # only English\n",
        "# train = train.filter(lambda x: x[\"language\"] == \"English\")\n",
        "# test = test.filter(lambda x: x[\"language\"] == \"English\")\n",
        "\n",
        "# # convert to pandas dataframe\n",
        "# train_df = pd.DataFrame(train)\n",
        "# test_df = pd.DataFrame(test)\n",
        "\n",
        "# # create binary labels where 1 = sensitive data and 0 = not sensitive\n",
        "# train_df[\"is_sensitive\"] = train_df[\"privacy_mask\"].apply(lambda x: 1 if len(x) > 0 else 0)\n",
        "# test_df[\"is_sensitive\"] = test_df[\"privacy_mask\"].apply(lambda x: 1 if len(x) > 0 else 0)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_df = pd.read_pickle(\"/content/drive/My Drive/CMPE 257/CMPE 257 Colab/257 Sensitive Data Input Guardrail/train_df_embedding.pkl\")\n",
        "test_df = pd.read_pickle(\"/content/drive/My Drive/CMPE 257/CMPE 257 Colab/257 Sensitive Data Input Guardrail/test_df_embedding.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxWHPjmPK8-z",
        "outputId": "862a1d4c-ab56-41b9-cedf-235ff828a9c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gilV7vxUK4wt",
        "outputId": "8fe78c0e-b15d-4c78-e08c-2d752d0bb28e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8504908129876667\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.91      0.58       908\n",
            "           1       0.99      0.84      0.91      7038\n",
            "\n",
            "    accuracy                           0.85      7946\n",
            "   macro avg       0.71      0.88      0.75      7946\n",
            "weighted avg       0.92      0.85      0.87      7946\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# tf-idf vectorization on source_text, 2300 max_features produced best accuracy\n",
        "vectorizer = TfidfVectorizer(max_features = 2300, ngram_range = (1,2), stop_words = \"english\")\n",
        "\n",
        "X_train = vectorizer.fit_transform(train_df[\"source_text\"])\n",
        "X_test = vectorizer.transform(test_df[\"source_text\"])\n",
        "\n",
        "y_train = train_df[\"is_sensitive\"]\n",
        "y_test = test_df[\"is_sensitive\"]\n",
        "\n",
        "# logistic regression, 20 iterations produced best accuracy\n",
        "clf = LogisticRegression(max_iter = 20, class_weight = \"balanced\", n_jobs = -1)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred)))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddings and PCA with 80% variance\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# building feature matrices from embedding column\n",
        "X_train = np.vstack(train_df[\"embedding\"].values)  # shape - (n_train, embedding_dim)\n",
        "X_test  = np.vstack(test_df[\"embedding\"].values)   # shape - (n_test, embedding_dim)\n",
        "\n",
        "y_train = train_df[\"is_sensitive\"].values\n",
        "y_test  = test_df[\"is_sensitive\"].values\n",
        "\n",
        "\n",
        "# scaling embeddings before logistic regression\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# fit pca with 114 components\n",
        "pca = PCA(n_components = 114) # 114 components to capture 80% of variance\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "\n",
        "# logistic regression on embeddings\n",
        "# more iterations, since embeddings can be high-dim\n",
        "clf = LogisticRegression(max_iter = 30, class_weight = \"balanced\", n_jobs = -1)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuRSBtbO_EQp",
        "outputId": "d0e91fbe-ab06-4baf-bc99-51b14c759c77"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8672287943619431\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.92      0.61       908\n",
            "           1       0.99      0.86      0.92      7038\n",
            "\n",
            "    accuracy                           0.87      7946\n",
            "   macro avg       0.72      0.89      0.77      7946\n",
            "weighted avg       0.93      0.87      0.88      7946\n",
            "\n"
          ]
        }
      ]
    }
  ]
}