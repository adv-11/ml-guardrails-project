{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PW5X6c7sOyKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6f3140b7-9e3e-43cd-e298-fa9b7e37c315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_df = pd.read_pickle(\"/content/drive/My Drive/CMPE 257/CMPE 257 Colab/257 Sensitive Data Input Guardrail/train_df_embedding.pkl\")\n",
        "test_df = pd.read_pickle(\"/content/drive/My Drive/CMPE 257/CMPE 257 Colab/257 Sensitive Data Input Guardrail/test_df_embedding.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# vectorize text with TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features = 1500, ngram_range = (1, 2), stop_words = \"english\")\n",
        "\n",
        "# svm, make sure to adjust c\n",
        "svm_pipeline = Pipeline([(\"tfidf\", vectorizer),(\"svm\", LinearSVC(C = 10))])\n",
        "\n",
        "# train model\n",
        "svm_pipeline.fit(train_df[\"source_text\"], train_df[\"is_sensitive\"])\n",
        "\n",
        "# evaluate\n",
        "y_pred = svm_pipeline.predict(test_df[\"source_text\"])\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(test_df[\"is_sensitive\"], y_pred))\n",
        "print(classification_report(test_df[\"is_sensitive\"], y_pred, target_names = [\"Not Sensitive\", \"Sensitive\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McSFKUMtlK_J",
        "outputId": "59aeb18b-06ce-4fc0-bbfa-6ebb32943f4a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.916058394160584\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Not Sensitive       0.64      0.60      0.62       908\n",
            "    Sensitive       0.95      0.96      0.95      7038\n",
            "\n",
            "     accuracy                           0.92      7946\n",
            "    macro avg       0.79      0.78      0.79      7946\n",
            " weighted avg       0.91      0.92      0.91      7946\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddings and PCA with 80% variance\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# building feature matrices from embedding column\n",
        "X_train = np.vstack(train_df[\"embedding\"].values)  # shape - (n_train, embedding_dim)\n",
        "X_test  = np.vstack(test_df[\"embedding\"].values)   # shape - (n_test, embedding_dim)\n",
        "\n",
        "y_train = train_df[\"is_sensitive\"].values\n",
        "y_test  = test_df[\"is_sensitive\"].values\n",
        "\n",
        "\n",
        "# scaling embeddings before logistic regression\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# fit pca with 114 components\n",
        "pca = PCA(n_components = 114) # 114 components to capture 80% of variance\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "# svm, make sure to adjust c\n",
        "svm_pipeline = Pipeline([(\"pca\", pca),(\"svm\", LinearSVC(C = 10))])\n",
        "\n",
        "# train model\n",
        "svm_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# evaluate\n",
        "y_pred = svm_pipeline.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(test_df[\"is_sensitive\"], y_pred))\n",
        "print(classification_report(test_df[\"is_sensitive\"], y_pred, target_names = [\"Not Sensitive\", \"Sensitive\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZme2V7aPLTZ",
        "outputId": "f0c82efe-e75b-4aab-c34e-e08485a1b662"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.929146740498364\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Not Sensitive       0.74      0.59      0.66       908\n",
            "    Sensitive       0.95      0.97      0.96      7038\n",
            "\n",
            "     accuracy                           0.93      7946\n",
            "    macro avg       0.84      0.78      0.81      7946\n",
            " weighted avg       0.92      0.93      0.93      7946\n",
            "\n"
          ]
        }
      ]
    }
  ]
}